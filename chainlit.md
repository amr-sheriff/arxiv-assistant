# Welcome to arXiv Assistant! ðŸš€ðŸ¤–

This project is a demonstration of how to prototype a Retrieval-Augmented Generation (RAG) Assistant employing a suite of open-source technologies, frameworks and fine-tuned Large Language Models.

It can be adapted to many other business-specific use cases.

The arXiv Assistant is a simple demo designed to help researchers and practitioners stay up-to-date with the latest advancements in various fields by retrieving, summarizing, and answering queries about research papers from arXiv.

The assistant can retrieve and select relevant research papers based on user-specified criteria such as submission/revision date, domain/category, and topic. Additionally, it can also answer questions about the papers and highlight key points.

## How to use ðŸ‘‡

Start by entering a topic:
- FlashAttention
- RAG papers in year 2024
- What's FlashAttention?
- Tell me about Transformers Models in NLP

Then Ask questions:
- Explain Flash Attention 2
- Summarize this paper in 3 paragraphs 'FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning'
- What are the advantages of flash attention 2? Mention them in bullet points
- Who are the authors of Flash Attention 2 paper?

## Notes

- To change the topic, start a new conversation

